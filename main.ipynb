{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b69e32c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preview:\n",
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0            7.4              0.70         0.00             1.9      0.076   \n",
      "1            7.8              0.88         0.00             2.6      0.098   \n",
      "2            7.8              0.76         0.04             2.3      0.092   \n",
      "3           11.2              0.28         0.56             1.9      0.075   \n",
      "4            7.4              0.70         0.00             1.9      0.076   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
      "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
      "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
      "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "\n",
      "   alcohol  quality  Id  \n",
      "0      9.4        5   0  \n",
      "1      9.8        5   1  \n",
      "2      9.8        5   2  \n",
      "3      9.8        6   3  \n",
      "4      9.4        5   4  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from ndlinear import NdLinear\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "data = pd.read_csv(\"WineQT.csv\")\n",
    "data = data.dropna()\n",
    "print(\"Data preview:\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f526bbe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in dataset: ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol', 'quality', 'Id']\n",
      "Dataset shape: (1143, 13)\n",
      "X_train_tensor shape: torch.Size([914, 11])\n",
      "y_train_tensor shape: torch.Size([914, 1])\n",
      "NdLinear MSE: 2.8268\n",
      "nn.Linear MSE: 2.3884\n",
      "NdLinear MSE: 2.8268\n",
      "nn.Linear MSE: 2.3884\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns in dataset:\", data.columns.tolist())\n",
    "print(\"Dataset shape:\", data.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "print(\"X_train_tensor shape:\", X_train_tensor.shape)\n",
    "print(\"y_train_tensor shape:\", y_train_tensor.shape)\n",
    "\n",
    "# NdLinear Model (Ensemble AI)\n",
    "class NdLinearModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(NdLinearModel, self).__init__()\n",
    "        self.ndlinear = NdLinear(input_dims=(input_dim,), hidden_size=(64,))\n",
    "        self.output = nn.Linear(64, 1)\n",
    "    def forward(self, x):\n",
    "        x = self.ndlinear(x) \n",
    "        x = torch.relu(x)\n",
    "        x = self.output(x)  \n",
    "        return x\n",
    "# Train NdLinear model\n",
    "input_dim = X_train_scaled.shape[1]\n",
    "ndlinear_model = NdLinearModel(input_dim=input_dim)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(ndlinear_model.parameters(), lr=0.001)\n",
    "for epoch in range(200):\n",
    "    ndlinear_model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = ndlinear_model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "ndlinear_model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_ndlinear = ndlinear_model(X_test_tensor).numpy().flatten()\n",
    "    y_pred_ndlinear = np.clip(y_pred_ndlinear, 3, 8)  # Clip to valid quality range\n",
    "mse_ndlinear = mean_squared_error(y_test, y_pred_ndlinear)\n",
    "#  nn.Linear Model\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, 64)\n",
    "        self.output = nn.Linear(64, 1)\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "# Train nn.Linear model\n",
    "linear_model = LinearModel(input_dim=input_dim)\n",
    "optimizer = optim.Adam(linear_model.parameters(), lr=0.001)\n",
    "for epoch in range(200):\n",
    "    linear_model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = linear_model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "linear_model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_linear = linear_model(X_test_tensor).numpy().flatten()\n",
    "    y_pred_linear = np.clip(y_pred_linear, 3, 8)  # Clip to valid quality range\n",
    "mse_linear = mean_squared_error(y_test, y_pred_linear)\n",
    "\n",
    "\n",
    "print(f\"NdLinear MSE: {mse_ndlinear:.4f}\")\n",
    "print(f\"nn.Linear MSE: {mse_linear:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5d72bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold CV results with K=3:\n",
      "NdLinear average MSE: 2.3665987354604794\n",
      "nn.Linear average MSE: 2.4035062378541854\n"
     ]
    }
   ],
   "source": [
    "## KFold Cross-Validation\n",
    "\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=10)\n",
    "ndlinear_mse_scores = []\n",
    "linear_mse_scores = []\n",
    "for train_index, val_index in kf.split(X_train_scaled):\n",
    "\n",
    "    X_train_fold = X_train_scaled[train_index]\n",
    "    y_train_fold = y_train[train_index]\n",
    "    X_val_fold = X_train_scaled[val_index]\n",
    "    y_val_fold = y_train[val_index]\n",
    "\n",
    "    X_train_fold_tensor = torch.tensor(X_train_fold, dtype=torch.float32)\n",
    "    y_train_fold_tensor = torch.tensor(y_train_fold, dtype=torch.float32).reshape(-1, 1)\n",
    "    X_val_fold_tensor = torch.tensor(X_val_fold, dtype=torch.float32)\n",
    "    y_val_fold_tensor = torch.tensor(y_val_fold, dtype=torch.float32).reshape(-1, 1)\n",
    "    # Train NdLinear model\n",
    "    ndlinear_model_cv = NdLinearModel(input_dim=input_dim)\n",
    "    optimizer_nd = optim.Adam(ndlinear_model_cv.parameters(), lr=0.001)\n",
    "    for epoch in range(200):\n",
    "        ndlinear_model_cv.train()\n",
    "        optimizer_nd.zero_grad()\n",
    "        outputs = ndlinear_model_cv(X_train_fold_tensor)\n",
    "        loss = criterion(outputs, y_train_fold_tensor)\n",
    "        loss.backward()\n",
    "        optimizer_nd.step()\n",
    "    ndlinear_model_cv.eval()\n",
    "    with torch.no_grad():\n",
    "        y_val_pred = ndlinear_model_cv(X_val_fold_tensor).numpy().flatten()\n",
    "        y_val_pred = np.clip(y_val_pred, 3, 8)\n",
    "        mse_cv = mean_squared_error(y_val_fold, y_val_pred)\n",
    "        ndlinear_mse_scores.append(mse_cv)\n",
    "    #Train nn.Linear model \n",
    "    linear_model_cv = LinearModel(input_dim=input_dim)\n",
    "    optimizer_lin = optim.Adam(linear_model_cv.parameters(), lr=0.001)\n",
    "    for epoch in range(200):\n",
    "        linear_model_cv.train()\n",
    "        optimizer_lin.zero_grad()\n",
    "        outputs = linear_model_cv(X_train_fold_tensor)\n",
    "        loss = criterion(outputs, y_train_fold_tensor)\n",
    "        loss.backward()\n",
    "        optimizer_lin.step()\n",
    "    linear_model_cv.eval()\n",
    "    with torch.no_grad():\n",
    "        y_val_pred_lin = linear_model_cv(X_val_fold_tensor).numpy().flatten()\n",
    "        y_val_pred_lin = np.clip(y_val_pred_lin, 3, 8)  # Clip to valid quality range\n",
    "        mse_cv_lin = mean_squared_error(y_val_fold, y_val_pred_lin)\n",
    "        linear_mse_scores.append(mse_cv_lin)\n",
    "\n",
    "print(f\"KFold CV results with K=3:\")\n",
    "print(\"NdLinear average MSE:\", np.mean(ndlinear_mse_scores))\n",
    "print(\"nn.Linear average MSE:\", np.mean(linear_mse_scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
